<p align="left">
  <img src="../doc/logo.png" width="30%">
</p>

# Infinity SenseFit API [0.2.0]

<p align="center">
  <img src="../doc/sensefit_teaser.gif" width="70%">
</p>

The SenseFit API generates synthetic data for applications at the intersection of on-body **sens**ing (e.g. IMU) and **fit**ness. The API currently allows users to generate simulated time series corresponding to angular position data captured at the wrist (e.g. with a smart watch). Ground-truth labels include continuous, per-frame rep counts.

This folder contains the following tutorial notebooks:

- [explore_api_parameters.ipynb](explore_api_parameters.ipynb): This notebook shows how to (1) submit a job to the remote API endpoint for generating synthetic IMU (angular position) data, and (2) visualize the resulting time series + motion videos. It goes through different API parameters to show how they can be used for generating specifically curated synthetic datasets.

- [large_job_demo.ipynb](large_job_demo.ipynb): This notebook shows how to submit many (100s) of jobs in a single batch, query their status in non-blocking mode, and compile the dataset's metadata into a dataframe for easy summarization/querying.

- [rep_counting_demo.ipynb](rep_counting_demo.ipynb): This notebook shows how synthetic data generated by the SenseFit API can be used to (1) train a rep counting model that generalizes to the real world, and (2) iteratively improve a model's performance by generating synthetic data around specific failure modes.

## Parameter Description

For convenience, we provide the parameters of the SenseFit API along with their input constraints below. All parameter ranges are inclusive.

- `exercise`: Name of exercise used in the animation. Reference videos and metadata for each exercise are available [here](https://docs.google.com/spreadsheets/d/15Ofjc0dA6IDihMzQguEiB0KxwjWSnMw1moIJglRyTCk/edit#gid=703635996).
  - String that must be one of:
    - ARM_RAISE-DUMBBELL
    - BEAR_CRAWL-HOLDS
    - BICEP_CURL-ALTERNATING-DUMBBELL
    - BICEP_CURL-BARBELL
    - BICEP_CURL-DUMBBELL
    - BIRD_DOG
    - BRIDGE
    - BURPEE
    - CLAMSHELL-LEFT
    - CLAMSHELL-RIGHT
    - CRUNCHES
    - DEADLIFT-DUMBBELL
    - DONKEY_KICK-LEFT
    - DONKEY_KICK-RIGHT
    - DOWNWARD_DOG
    - HAMMER_CURL-DUMBBELL
    - LUNGE-CROSSBACK
    - OVERHEAD_PRESS-DUMBBELL
    - PRESS-SINGLE_ARM-DUMBBELL-LEFT
    - PRESS-SINGLE_ARM-DUMBBELL-RIGHT
    - PUSHUP
    - PUSHUP-CLOSE_GRIP
    - PUSHUP-EXPLOSIVE
    - PUSH_PRESS-SINGLE_ARM-DUMBBELL-LEFT
    - PUSH_PRESS-SINGLE_ARM-DUMBBELL-RIGHT
    - SITUP
    - SPLIT_SQUAT-SINGLE_ARM-DUMBBELL-LEFT
    - SPLIT_SQUAT-SINGLE_ARM-DUMBBELL-RIGHT
    - SQUAT-BACK-BARBELL
    - SQUAT-BODYWEIGHT
    - SQUAT-GOBLET+SUMO-DUMBBELL
    - TRICEP_KICKBACK-BENT_OVER+SINGLE_ARM-DUMBBELL-LEFT
    - TRICEP_KICKBACK-BENT_OVER+SINGLE_ARM-DUMBBELL-RIGHT
    - UPPERCUT-LEFT
    - UPPERCUT-RIGHT
    - V_UP
  - Default value: BICEP_CURL-DUMBBELL
- `num_reps`: Number of exercise repetitions in the returned time series data.
  - Integer in range of 1 to 20
  - Default value: 1
- `watch_location`: Wrist where device will be placed.
  - String that must be one of: LEFT, RIGHT
  - Default value: LEFT
- `crown_orientation`: Which side the watch crown should point (from first-person perspective).
  - String that must be one of: LEFT, RIGHT
  - Default value: RIGHT
- `ref_xy_rotation`: Rotation (in XY plane) of reference orientation in radians (simulates [xArbitraryZVertical](https://developer.apple.com/documentation/coremotion/cmattitudereferenceframe/1615953-xarbitraryzvertical) behavior on Apple Watch).
  - Float in range of 0.0 to 6.2831
  - Default value: 0.0
- `rel_baseline_speed`: Baseline speed of animation, relative to default (natural) speed.
  - Float in range of 0.33 to 3.0
  - Default value: 1.0
- `max_rel_speed_change`: Maximum speed change introduced, relative to baseline speed.
  - Float in range of 0.0 to 1.0
  - Default value: 0.0
- `trim_start_frac`: Fraction of seed animation (from start to midpoint) to truncate at the start.
  - Float in range of 0.0 to 0.9
  - Default value: 0.0
  - `trim_start_frac + trim_end_frac` cannot exceed 0.9
  - Note: this parameter is disabled for some exercises (see `allow_trim` [here](https://docs.google.com/spreadsheets/d/15Ofjc0dA6IDihMzQguEiB0KxwjWSnMw1moIJglRyTCk/edit#gid=703635996))
- `trim_end_frac`: Fraction of seed animation (from start to midpoint) to truncate at the end.
  - Float in range of 0.0 to 0.9
  - Default value: 0.0
  - `trim_start_frac + trim_end_frac` cannot exceed 0.9
  - Note: this parameter is disabled for some exercises (see `allow_trim` [here](https://docs.google.com/spreadsheets/d/15Ofjc0dA6IDihMzQguEiB0KxwjWSnMw1moIJglRyTCk/edit#gid=703635996))
- `kinematic_noise_factor`: Scaling factor used to adjust the amount of kinematic noise added in the simulated movement.
  - Float in range of 0.0 to 2.0
  - Default value: 1.0
- `wrist_offset_deg`: Fixed rotation offset applied to supination/pronation axis of wrists, in degrees. Negative values correspond to supination.
  - Float in range of -90.0 to 90.0 
  - Default value: 0.0
- `randomize_body_shape`: If True, the SMPL-X body shape will be randomized.
  - Boolean
  - Default value: False
- `use_random_motion`:  If True, random motion will be used for the animation (rather than exercise repetitions).
  - Boolean
  - Default value: False
- `num_random_frames`: Number of random frames to export if using random motion.
  - Integer in range of 10 to 500
  - Default value: 100
- `frames_per_second`: Sampling rate of exported time series and video.
  - Integer that must be one of: 20, 30, 40
  - Default value: 20
- `image_width`: Width dimension of rendered video, in pixels.
  - Integer in range of 224 to 1024
  - Default value: 480
- `image_height`: Height dimension of rendered video, in pixels.
  - Integer in range of 224 to 1024
  - Default value: 480
- `random_seed`: Random seed used for reproducibility.
  - Integer in the range of 0 to 2^31-1
  - Default value: 100

An example parameterization for the SenseFit API expressed as a Python `dict`:

```
params_dict = {
	"exercise": "BICEP_CURL-DUMBBELL",
	"num_reps": 5,
	"watch_location": "LEFT",
	"crown_orientation": "RIGHT",
	"rel_baseline_speed": 2.11,
	"max_rel_speed_change": 0.28,
	"trim_start_frac": 0.17,
	"trim_end_frac": 0.10,
	"kinematic_noise_factor": 0.82,
	"wrist_offset_deg": -18.2,
	"ref_xy_rotation": 5.30,
	"frames_per_second": 20,
	"randomize_body_shape": True,
	"random_seed": 387
}
```


## API Outputs
For each job, a zipped archive can be downloaded that includes the following files:

- `job.json`: Contains parameters that were used for job submission.
- `data.csv`: Contains synthetic angular position data and ground truth rep count labels. 
  - The angular position data is provided in the form of 3D rotation matrices (see [below](#how-to-use-synthetic-data-with-real-world-data)). Column headers for the rotation matrix data are formatted as `rotation_matrix_m{row}{column}`. 
  - Two versions of rep count labels are provided. `rep_count_from_start`  is indexed relative to the start of the video. It considers the pose visualized in the first frame of the video to be the starting (and ending) position of a rep. `rep_count_from_intermediate` is instead indexed to the intermediate (midpoint) pose of the rep sequence. For example, if `rep_count_from_start` is indexed to the point of most extension, then `rep_count_from_intermediate` is indexed to the point of most flexion. We provide both since users may wish to define the point of most flexion OR the point of most extension as the rep inflection point.
- `video.mp4`: Video of the animated armature and mesh corresponding to the generated IMU data. The 3-axis coordinate system visualized on the wrist represents the simulated orientation of the device. The other (non-moving) 3-axis coordinate system that is visualized represents the reference orientation. The data provided in `data.csv` is the relative difference between these two orientations.

## How to use synthetic data with real world data
 
We provide angular position in 3D rotation matrix representation since (1) we have confirmed these match the rotation matrices sampled directly from the [CoreMotion SDK](https://developer.apple.com/documentation/coremotion), and (2) a convenient continuous representation that can be used for ML models is simply the first two columns of the rotation matrix [[ref](https://arxiv.org/abs/1812.07035)].